{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                Scania APS Component failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Problem statement.\n",
    "\n",
    "Data Source: https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks\n",
    "\n",
    "**Data:** Scania Trucks Sensor data\n",
    "\n",
    "**Problem statement :**\n",
    "- The system in focus is the Air Pressure system (APS) which generates pressurized air that are utilized in various functions in a truck, such as braking and gear changes. The datasets positive class corresponds to component failures for a specific component of the APS system. The negative class corresponds to trucks with failures for components not related to the APS system.\n",
    "\n",
    "- The problem is to reduce the cost due to unnecessary repairs. So it is required to minimize the false predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|True class | Positive | Negative ||\n",
    "| ----------- | ----------- |   |  |\n",
    "|<b>Predicted class</b>|||\n",
    "| Positive      |   -       | cost_1  |    |\n",
    "| Negative   | cost_2        |  | |\n",
    "\n",
    "\n",
    "Cost_1 = 10 and Cost_2 = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The total cost of a prediction model the sum of `Cost_1` multiplied by the number of Instances with type 1 failure and `Cost_2` with the number of instances with type 2 failure, resulting in a `Total_cost`. In this case Cost_1 refers to the cost that an unnessecary check needs to be done by an mechanic at an workshop, while Cost_2 refer to the cost of missing a faulty truck, which may cause a breakdown. `Total_cost = Cost_1 * No_Instances + Cost_2 * No_Instances.`\n",
    "\n",
    "- From the above problem statement we could observe that, we have to reduce false positives and false negatives. More importantly we have to **reduce false negatives, since cost incurred due to false negative is 50 times higher than the false positives.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and other objectives\n",
    "\n",
    "- Need to Handle many Null values in almost all columns\n",
    "- No low-latency requirement.\n",
    "- Interpretability is not important.\n",
    "- misclassification leads the unecessary repair costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_mode\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\iNeuron\\Data Squad\\ML-Projects\\Scania Truck Air pressure\\aps_failure_training_set.csv', na_values=\"na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 171)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    59000\n",
       "pos     1000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 170 numerical features : ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n",
      "\n",
      "We have 1 categorical features : ['class']\n"
     ]
    }
   ],
   "source": [
    "# define numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "missing = df.isna().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending = False)\n",
    "\n",
    "ax.bar(missing.index, missing.values.T[0])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Percentage missing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br_000</th>\n",
       "      <td>82.106667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bq_000</th>\n",
       "      <td>81.203333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp_000</th>\n",
       "      <td>79.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo_000</th>\n",
       "      <td>77.221667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_000</th>\n",
       "      <td>77.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cr_000</th>\n",
       "      <td>77.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn_000</th>\n",
       "      <td>73.348333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "br_000  82.106667\n",
       "bq_000  81.203333\n",
       "bp_000  79.566667\n",
       "bo_000  77.221667\n",
       "ab_000  77.215000\n",
       "cr_000  77.215000\n",
       "bn_000  73.348333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropcols = missing[missing[0]>70]\n",
    "dropcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(dropcols.index), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 164)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    59000\n",
       "pos     1000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 1000, Negative: 59000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = df[df['class']=='pos'].shape[0]\n",
    "neg = df[df['class']=='neg'].shape[0]\n",
    "print(\"Positive: \" + str(pos) + \", Negative: \" + str(neg))\n",
    "sns.catplot(data=df, x=\"class\", kind=\"count\", palette=\"winter_r\", alpha=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(test_y, predict_y):\n",
    "    '''\n",
    "    This function takes y_ture, y_predicted, and prints Total cost due to misclassification\n",
    "   \n",
    "    '''\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    cost_1 = 10*C[0][1]\n",
    "    cost_2 = 500*C[1][0]\n",
    "    total = (cost_1 + cost_2)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.29765243902439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count= df.isnull().sum()\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "(total_missing/total_cells) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9840000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521289"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "knn = KNNImputer(n_neighbors = 3)\n",
    "data = knn.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y= y.replace({'pos': 1, 'neg': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94392, 163), (23598, 163))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, predicted):\n",
    "    acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "    precision = precision_score(true, predicted) # Calculate Precision\n",
    "    recall = recall_score(true, predicted)  # Calculate Recall\n",
    "    roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9959\n",
      "- F1 score: 0.9958\n",
      "- Precision: 0.9924\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9959\n",
      "- COST: 4890.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9917\n",
      "- F1 score: 0.9916\n",
      "- Precision: 0.9878\n",
      "- Recall: 0.9955\n",
      "- Roc Auc Score: 0.9918\n",
      "- COST: 27430.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9849\n",
      "- F1 score: 0.9850\n",
      "- Precision: 0.9820\n",
      "- Recall: 0.9879\n",
      "- Roc Auc Score: 0.9848\n",
      "- COST: 295070.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9842\n",
      "- F1 score: 0.9840\n",
      "- Precision: 0.9795\n",
      "- Recall: 0.9885\n",
      "- Roc Auc Score: 0.9843\n",
      "- COST: 68900.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9486\n",
      "- F1 score: 0.9479\n",
      "- Precision: 0.9651\n",
      "- Recall: 0.9314\n",
      "- Roc Auc Score: 0.9487\n",
      "- COST: 1641470.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9491\n",
      "- F1 score: 0.9474\n",
      "- Precision: 0.9639\n",
      "- Recall: 0.9314\n",
      "- Roc Auc Score: 0.9488\n",
      "- COST: 402050.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9882\n",
      "- F1 score: 0.9884\n",
      "- Precision: 0.9775\n",
      "- Recall: 0.9996\n",
      "- Roc Auc Score: 0.9882\n",
      "- COST: 20900.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9839\n",
      "- F1 score: 0.9839\n",
      "- Precision: 0.9690\n",
      "- Recall: 0.9992\n",
      "- Roc Auc Score: 0.9841\n",
      "- COST: 8210.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9969\n",
      "- F1 score: 0.9969\n",
      "- Precision: 0.9945\n",
      "- Recall: 0.9992\n",
      "- Roc Auc Score: 0.9969\n",
      "- COST: 5140.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9991\n",
      "- F1 score: 0.9991\n",
      "- Precision: 0.9988\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9991\n",
      "- COST: 13590.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9956\n",
      "- F1 score: 0.9955\n",
      "- Precision: 0.9924\n",
      "- Recall: 0.9986\n",
      "- Roc Auc Score: 0.9956\n",
      "- COST: 8890.\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9432\n",
      "- F1 score: 0.9431\n",
      "- Precision: 0.9497\n",
      "- Recall: 0.9365\n",
      "- Roc Auc Score: 0.9433\n",
      "- COST: 1527500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9440\n",
      "- F1 score: 0.9428\n",
      "- Precision: 0.9470\n",
      "- Recall: 0.9386\n",
      "- Roc Auc Score: 0.9439\n",
      "- COST: 362100.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9761\n",
      "- F1 score: 0.9762\n",
      "- Precision: 0.9770\n",
      "- Recall: 0.9754\n",
      "- Roc Auc Score: 0.9761\n",
      "- COST: 593370.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9756\n",
      "- F1 score: 0.9752\n",
      "- Precision: 0.9749\n",
      "- Recall: 0.9755\n",
      "- Roc Auc Score: 0.9756\n",
      "- COST: 144910.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_train_evaluation(models_dictionary):\n",
    "    cost_list=[]\n",
    "    models_list = []\n",
    "    \n",
    "    for i in range(len(list(models_dictionary))):\n",
    "        model = list(models_dictionary.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "        model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "        train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "        # Test set performance\n",
    "        model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "        model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "        test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "        print(list(models_dictionary.keys())[i])\n",
    "        models_list.append(list(models_dictionary.keys())[i])\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        print(f'- COST: {train_cost}.')\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        print(f'- COST: {test_cost}.')\n",
    "        accuracy_list.append(model_test_accuracy)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "        \n",
    "        report=pd.DataFrame(list(zip(models_list, accuracy_list)), columns=['Model Name', 'Cost']).sort_values(by=[\"Cost\"])\n",
    "        \n",
    "        return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 =pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.79250729e-02, 9.99999832e-01, 3.26176944e-08, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.20361295e-02, 0.00000000e+00, 1.46779625e-08, ...,\n",
       "        3.93692728e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.49423061e-02, 1.07006746e-07, 1.16491766e-08, ...,\n",
       "        1.34905375e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [4.07782233e-05, 9.99999829e-01, 2.09685178e-09, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.92336170e-02, 9.99999829e-01, 5.75469322e-08, ...,\n",
       "        1.01945944e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.46444794e-02, 3.27590826e-07, 7.31568288e-08, ...,\n",
       "        4.14689673e-05, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTEENN(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(data1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93026, 163), (23257, 163))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9975\n",
      "- F1 score: 0.9976\n",
      "- Precision: 0.9956\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9975\n",
      "- COST: 3510.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9930\n",
      "- F1 score: 0.9930\n",
      "- Precision: 0.9905\n",
      "- Recall: 0.9955\n",
      "- Roc Auc Score: 0.9930\n",
      "- COST: 27110.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9876\n",
      "- F1 score: 0.9878\n",
      "- Precision: 0.9870\n",
      "- Recall: 0.9887\n",
      "- Roc Auc Score: 0.9876\n",
      "- COST: 273650.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9856\n",
      "- F1 score: 0.9856\n",
      "- Precision: 0.9847\n",
      "- Recall: 0.9866\n",
      "- Roc Auc Score: 0.9856\n",
      "- COST: 79790.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9635\n",
      "- F1 score: 0.9634\n",
      "- Precision: 0.9823\n",
      "- Recall: 0.9452\n",
      "- Roc Auc Score: 0.9638\n",
      "- COST: 1303070.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9635\n",
      "- F1 score: 0.9630\n",
      "- Precision: 0.9803\n",
      "- Recall: 0.9462\n",
      "- Roc Auc Score: 0.9636\n",
      "- COST: 315220.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9983\n",
      "- F1 score: 0.9984\n",
      "- Precision: 0.9969\n",
      "- Recall: 0.9999\n",
      "- Roc Auc Score: 0.9983\n",
      "- COST: 4490.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9966\n",
      "- F1 score: 0.9966\n",
      "- Precision: 0.9939\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9966\n",
      "- COST: 4720.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9987\n",
      "- F1 score: 0.9987\n",
      "- Precision: 0.9979\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9987\n",
      "- COST: 3250.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9997\n",
      "- F1 score: 0.9997\n",
      "- Precision: 0.9996\n",
      "- Recall: 0.9997\n",
      "- Roc Auc Score: 0.9997\n",
      "- COST: 6670.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9979\n",
      "- F1 score: 0.9979\n",
      "- Precision: 0.9967\n",
      "- Recall: 0.9991\n",
      "- Roc Auc Score: 0.9979\n",
      "- COST: 5390.\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9788\n",
      "- F1 score: 0.9789\n",
      "- Precision: 0.9894\n",
      "- Recall: 0.9686\n",
      "- Roc Auc Score: 0.9790\n",
      "- COST: 745890.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9793\n",
      "- F1 score: 0.9792\n",
      "- Precision: 0.9884\n",
      "- Recall: 0.9701\n",
      "- Roc Auc Score: 0.9793\n",
      "- COST: 175330.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9775\n",
      "- F1 score: 0.9778\n",
      "- Precision: 0.9817\n",
      "- Recall: 0.9739\n",
      "- Roc Auc Score: 0.9776\n",
      "- COST: 625080.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9756\n",
      "- F1 score: 0.9755\n",
      "- Precision: 0.9792\n",
      "- Recall: 0.9718\n",
      "- Roc Auc Score: 0.9756\n",
      "- COST: 166400.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "    model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "    train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "    model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "    test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "    print(f'- COST: {train_cost}.')\n",
    "\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "    print(f'- COST: {test_cost}.')\n",
    "\n",
    "    accuracy_list.append(test_cost)\n",
    "\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>4720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>27110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>79790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>166400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>175330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>315220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name    Cost\n",
       "5              XGBClassifier    3250\n",
       "0              Random Forest    3510\n",
       "4     K-Neighbors Classifier    4720\n",
       "6     CatBoosting Classifier    5390\n",
       "1              Decision Tree   27110\n",
       "2          Gradient Boosting   79790\n",
       "8        AdaBoost Classifier  166400\n",
       "7  Support Vector Classifier  175330\n",
       "3        Logistic Regression  315220"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(models_list, accuracy_list)), columns=['Model Name', 'Cost']).sort_values(by=[\"Cost\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mice forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "data2 = X.copy()\n",
    "kernel = mf.ImputationKernel(\n",
    "  data2,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1989\n",
    ")# Run the MICE algorithm for 3 iterations on each of the datasets\n",
    "kernel.mice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTEENN(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(data2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()\n",
    "X_res = minmax.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((92733, 163), (23184, 163))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9975\n",
      "- F1 score: 0.9975\n",
      "- Precision: 0.9957\n",
      "- Recall: 0.9992\n",
      "- Roc Auc Score: 0.9974\n",
      "- COST: 5000.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9930\n",
      "- F1 score: 0.9930\n",
      "- Precision: 0.9911\n",
      "- Recall: 0.9950\n",
      "- Roc Auc Score: 0.9930\n",
      "- COST: 30040.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9894\n",
      "- F1 score: 0.9896\n",
      "- Precision: 0.9885\n",
      "- Recall: 0.9907\n",
      "- Roc Auc Score: 0.9894\n",
      "- COST: 224430.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9881\n",
      "- F1 score: 0.9882\n",
      "- Precision: 0.9877\n",
      "- Recall: 0.9887\n",
      "- Roc Auc Score: 0.9881\n",
      "- COST: 67430.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9682\n",
      "- F1 score: 0.9683\n",
      "- Precision: 0.9835\n",
      "- Recall: 0.9536\n",
      "- Roc Auc Score: 0.9685\n",
      "- COST: 1105080.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9689\n",
      "- F1 score: 0.9685\n",
      "- Precision: 0.9842\n",
      "- Recall: 0.9533\n",
      "- Roc Auc Score: 0.9690\n",
      "- COST: 273280.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9935\n",
      "- F1 score: 0.9937\n",
      "- Precision: 0.9883\n",
      "- Recall: 0.9991\n",
      "- Roc Auc Score: 0.9934\n",
      "- COST: 26080.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9909\n",
      "- F1 score: 0.9910\n",
      "- Precision: 0.9837\n",
      "- Recall: 0.9985\n",
      "- Roc Auc Score: 0.9909\n",
      "- COST: 10920.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9984\n",
      "- F1 score: 0.9984\n",
      "- Precision: 0.9976\n",
      "- Recall: 0.9992\n",
      "- Roc Auc Score: 0.9984\n",
      "- COST: 4780.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9994\n",
      "- F1 score: 0.9994\n",
      "- Precision: 0.9992\n",
      "- Recall: 0.9996\n",
      "- Roc Auc Score: 0.9994\n",
      "- COST: 9370.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9973\n",
      "- F1 score: 0.9973\n",
      "- Precision: 0.9961\n",
      "- Recall: 0.9986\n",
      "- Roc Auc Score: 0.9973\n",
      "- COST: 8460.\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9825\n",
      "- F1 score: 0.9828\n",
      "- Precision: 0.9877\n",
      "- Recall: 0.9779\n",
      "- Roc Auc Score: 0.9826\n",
      "- COST: 528740.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9829\n",
      "- F1 score: 0.9829\n",
      "- Precision: 0.9883\n",
      "- Recall: 0.9776\n",
      "- Roc Auc Score: 0.9829\n",
      "- COST: 131850.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9818\n",
      "- F1 score: 0.9821\n",
      "- Precision: 0.9862\n",
      "- Recall: 0.9780\n",
      "- Roc Auc Score: 0.9819\n",
      "- COST: 527480.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9812\n",
      "- F1 score: 0.9812\n",
      "- Precision: 0.9855\n",
      "- Recall: 0.9769\n",
      "- Roc Auc Score: 0.9812\n",
      "- COST: 136170.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "    model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "    train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "    model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "    test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "    print(f'- COST: {train_cost}.')\n",
    "\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "    print(f'- COST: {test_cost}.')\n",
    "\n",
    "    accuracy_list.append(test_cost)\n",
    "\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>10920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>30040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>67430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>131850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>136170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>273280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name    Cost\n",
       "5              XGBClassifier    4780\n",
       "0              Random Forest    5000\n",
       "6     CatBoosting Classifier    8460\n",
       "4     K-Neighbors Classifier   10920\n",
       "1              Decision Tree   30040\n",
       "2          Gradient Boosting   67430\n",
       "7  Support Vector Classifier  131850\n",
       "8        AdaBoost Classifier  136170\n",
       "3        Logistic Regression  273280"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(models_list, accuracy_list)), columns=['Model Name', 'Cost']).sort_values(by=[\"Cost\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CONSTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 =pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(data3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94374, 163), (23594, 163))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9960\n",
      "- F1 score: 0.9960\n",
      "- Precision: 0.9930\n",
      "- Recall: 0.9990\n",
      "- Roc Auc Score: 0.9961\n",
      "- COST: 6820.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9909\n",
      "- F1 score: 0.9908\n",
      "- Precision: 0.9873\n",
      "- Recall: 0.9944\n",
      "- Roc Auc Score: 0.9910\n",
      "- COST: 33990.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9831\n",
      "- F1 score: 0.9832\n",
      "- Precision: 0.9797\n",
      "- Recall: 0.9867\n",
      "- Roc Auc Score: 0.9831\n",
      "- COST: 324670.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9805\n",
      "- F1 score: 0.9804\n",
      "- Precision: 0.9753\n",
      "- Recall: 0.9855\n",
      "- Roc Auc Score: 0.9806\n",
      "- COST: 87400.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9567\n",
      "- F1 score: 0.9561\n",
      "- Precision: 0.9724\n",
      "- Recall: 0.9403\n",
      "- Roc Auc Score: 0.9567\n",
      "- COST: 1426630.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9558\n",
      "- F1 score: 0.9544\n",
      "- Precision: 0.9718\n",
      "- Recall: 0.9377\n",
      "- Roc Auc Score: 0.9556\n",
      "- COST: 365670.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9897\n",
      "- F1 score: 0.9898\n",
      "- Precision: 0.9808\n",
      "- Recall: 0.9990\n",
      "- Roc Auc Score: 0.9897\n",
      "- COST: 32250.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9846\n",
      "- F1 score: 0.9846\n",
      "- Precision: 0.9715\n",
      "- Recall: 0.9980\n",
      "- Roc Auc Score: 0.9848\n",
      "- COST: 14900.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9967\n",
      "- F1 score: 0.9966\n",
      "- Precision: 0.9939\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9967\n",
      "- COST: 4710.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9989\n",
      "- F1 score: 0.9989\n",
      "- Precision: 0.9983\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9989\n",
      "- COST: 13310.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9958\n",
      "- F1 score: 0.9957\n",
      "- Precision: 0.9926\n",
      "- Recall: 0.9989\n",
      "- Roc Auc Score: 0.9958\n",
      "- COST: 7370.\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9717\n",
      "- F1 score: 0.9716\n",
      "- Precision: 0.9791\n",
      "- Recall: 0.9642\n",
      "- Roc Auc Score: 0.9718\n",
      "- COST: 856240.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9706\n",
      "- F1 score: 0.9700\n",
      "- Precision: 0.9766\n",
      "- Recall: 0.9635\n",
      "- Roc Auc Score: 0.9705\n",
      "- COST: 215180.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9743\n",
      "- F1 score: 0.9744\n",
      "- Precision: 0.9751\n",
      "- Recall: 0.9737\n",
      "- Roc Auc Score: 0.9743\n",
      "- COST: 633290.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9722\n",
      "- F1 score: 0.9718\n",
      "- Precision: 0.9716\n",
      "- Recall: 0.9720\n",
      "- Roc Auc Score: 0.9722\n",
      "- COST: 166310.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "    model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "    train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "    model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "    test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "    print(f'- COST: {train_cost}.')\n",
    "\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "    print(f'- COST: {test_cost}.')\n",
    "\n",
    "    accuracy_list.append(test_cost)\n",
    "\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(data4, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94384, 163), (23596, 163))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9970\n",
      "- F1 score: 0.9970\n",
      "- Precision: 0.9949\n",
      "- Recall: 0.9990\n",
      "- Roc Auc Score: 0.9970\n",
      "- COST: 6590.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9927\n",
      "- F1 score: 0.9926\n",
      "- Precision: 0.9887\n",
      "- Recall: 0.9966\n",
      "- Roc Auc Score: 0.9928\n",
      "- COST: 21320.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9843\n",
      "- F1 score: 0.9844\n",
      "- Precision: 0.9817\n",
      "- Recall: 0.9871\n",
      "- Roc Auc Score: 0.9843\n",
      "- COST: 315210.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9836\n",
      "- F1 score: 0.9833\n",
      "- Precision: 0.9809\n",
      "- Recall: 0.9858\n",
      "- Roc Auc Score: 0.9836\n",
      "- COST: 84730.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9542\n",
      "- F1 score: 0.9535\n",
      "- Precision: 0.9712\n",
      "- Recall: 0.9365\n",
      "- Roc Auc Score: 0.9542\n",
      "- COST: 1516680.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9538\n",
      "- F1 score: 0.9522\n",
      "- Precision: 0.9714\n",
      "- Recall: 0.9337\n",
      "- Roc Auc Score: 0.9535\n",
      "- COST: 388190.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9893\n",
      "- F1 score: 0.9894\n",
      "- Precision: 0.9796\n",
      "- Recall: 0.9994\n",
      "- Roc Auc Score: 0.9892\n",
      "- COST: 23340.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9853\n",
      "- F1 score: 0.9853\n",
      "- Precision: 0.9719\n",
      "- Recall: 0.9991\n",
      "- Roc Auc Score: 0.9855\n",
      "- COST: 8360.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9981\n",
      "- F1 score: 0.9981\n",
      "- Precision: 0.9969\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9982\n",
      "- COST: 4360.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9995\n",
      "- Precision: 0.9995\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9995\n",
      "- COST: 11760.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9976\n",
      "- F1 score: 0.9976\n",
      "- Precision: 0.9959\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9977\n",
      "- COST: 4480.\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9737\n",
      "- F1 score: 0.9736\n",
      "- Precision: 0.9812\n",
      "- Recall: 0.9662\n",
      "- Roc Auc Score: 0.9738\n",
      "- COST: 810270.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9745\n",
      "- F1 score: 0.9739\n",
      "- Precision: 0.9806\n",
      "- Recall: 0.9673\n",
      "- Roc Auc Score: 0.9744\n",
      "- COST: 192220.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9751\n",
      "- F1 score: 0.9752\n",
      "- Precision: 0.9740\n",
      "- Recall: 0.9764\n",
      "- Roc Auc Score: 0.9751\n",
      "- COST: 570830.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9754\n",
      "- F1 score: 0.9751\n",
      "- Precision: 0.9741\n",
      "- Recall: 0.9761\n",
      "- Roc Auc Score: 0.9754\n",
      "- COST: 142020.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "accuracy_list=[]\n",
    "models_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "    model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "    train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "    model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "    test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    models_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "    print(f'- COST: {train_cost}.')\n",
    "\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "    print(f'- COST: {test_cost}.')\n",
    "\n",
    "    accuracy_list.append(test_cost)\n",
    "\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_scorer(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = 10*fp+500*fn\n",
    "    return cost\n",
    "\n",
    "my_func = make_scorer(my_scorer, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTEENN(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(data1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('pca', PCA()),\n",
       "                                       ('clf', LogisticRegression(n_jobs=-1))]),\n",
       "             n_jobs=-1, param_grid={'pca__n_components': range(10, 100)},\n",
       "             scoring=make_scorer(my_scorer, greater_is_better=False),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1) # initialising SVC classifier\n",
    "pca = PCA() # initialising PCA component\n",
    "\n",
    "pipe = Pipeline(steps=[(\"pca\",pca), (\"clf\",clf)]) # creating pipeline\n",
    "\n",
    "# hyperparameters grid to be investigated\n",
    "param_grid = {\n",
    "    'pca__n_components': range(10,100),\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=3, return_train_score=False, scoring=my_func, n_jobs=-1, verbose=3) # Grid Search with 3-fold CV\n",
    "search.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (CV score: -554043.333):\n",
      "{'pca__n_components': 98}\n"
     ]
    }
   ],
   "source": [
    "# Plotting best classificator\n",
    "print(\"Best parameters (CV score: {:0.3f}):\".format(search.best_score_))\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe5057b33890e8dd303e21b19623a3798ffaa8a05dcdf7dd3a35472e2b83b2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
